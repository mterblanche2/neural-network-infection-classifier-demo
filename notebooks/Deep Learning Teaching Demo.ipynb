{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:37.933597Z",
     "start_time": "2019-12-09T16:43:37.929595Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN ON LAPTOP\n",
    "# dir = 'D:/dev/teaching_repo/'\n",
    "nrows = 2000000\n",
    "\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.066595Z",
     "start_time": "2019-12-09T16:43:37.935598Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES & MODULES\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.layers import Dropout, Activation\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "# from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_targets(df):\n",
    "    scaler = LabelEncoder().fit(df)\n",
    "    labelled_target = to_categorical(scaler.transform(df))\n",
    "    print(labelled_target.shape)\n",
    "    return scaler, labelled_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:45.205597Z",
     "start_time": "2019-12-09T16:43:45.192594Z"
    }
   },
   "outputs": [],
   "source": [
    "# SHOW TRAINING PLOTS\n",
    "\n",
    "def plot_losses(history):\n",
    "    loss = history.history['loss'][2:]\n",
    "    val_loss = history.history['val_loss'][2:]\n",
    "    loss_epochs = range(1, len(loss) +1)\n",
    "    plt.clf()\n",
    "    plt.plot(loss_epochs, loss, 'bx', label='Training loss')\n",
    "    plt.plot(loss_epochs, val_loss, 'ro', label='Validation loss')\n",
    "    plt.title('Model training & validation loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc = 'upper left')\n",
    "    trainplot = plt.gcf()\n",
    "    plt.show()\n",
    "    trainplot.savefig(NAME + '--TRAINING PLOT.png', dpi=700)\n",
    "\n",
    "def plot_accuracy(history):\n",
    "    plt.clf()\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    val_acc = history.history['val_categorical_accuracy']\n",
    "    epochs = range(1, len(acc)+1)\n",
    "    plt.plot(epochs, acc, 'r.', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Model training & validation accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    trainplot_acc = plt.gcf()\n",
    "    plt.show()\n",
    "    trainplot_acc.savefig(NAME + '--ACC.png', dpi=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_small_model(neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], input_dim=10, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[1], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[2], kernel_initializer='uniform', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', metrics.categorical_accuracy])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def build_big_model(neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], input_dim=10, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[1], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[2], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[3], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[4], kernel_initializer='uniform', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', metrics.categorical_accuracy])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def build_medium_model(neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], input_dim=10, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[1], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[2], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(neurons[3], kernel_initializer='uniform', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', metrics.categorical_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.073601Z",
     "start_time": "2019-12-09T16:43:41.067595Z"
    }
   },
   "outputs": [],
   "source": [
    "# LOAD & PREPARE TRAIN DATA\n",
    "condition = 'TRAIN.csv'\n",
    "# os.chdir(\"neural-network-infection-classifier-demo\")\n",
    "model = 'INFECTION'\n",
    "date = dt.now().strftime('-%Y.%m.%d')\n",
    "NAME = model + date\n",
    "print(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.123596Z",
     "start_time": "2019-12-09T16:43:41.075599Z"
    }
   },
   "outputs": [],
   "source": [
    "# LOAD RAW DATA FILES\n",
    "train_data = pd.read_csv('TRAIN.csv', header=0, nrows=200000)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.150595Z",
     "start_time": "2019-12-09T16:43:41.125597Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('TEST.csv', header=0, nrows=50000)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.160597Z",
     "start_time": "2019-12-09T16:43:41.151596Z"
    }
   },
   "outputs": [],
   "source": [
    "# GENERATE INPUT FEATURES & LABELS\n",
    "X_train = train_data.iloc[:, 0:-1].values.astype('float32')\n",
    "X_test = test_data.iloc[:, 0:-1].values.astype('float32')\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.167597Z",
     "start_time": "2019-12-09T16:43:41.162597Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train_data.iloc[:, -1]\n",
    "y_test = test_data.iloc[:, -1]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.188597Z",
     "start_time": "2019-12-09T16:43:41.179596Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler, labelled_y_train = label_encode_targets(y_train)\n",
    "scaler, labelled_y_test = label_encode_targets(y_test)\n",
    "\n",
    "print(labelled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.200596Z",
     "start_time": "2019-12-09T16:43:41.196595Z"
    }
   },
   "outputs": [],
   "source": [
    "print('SCALER CLASSES:', scaler.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.209596Z",
     "start_time": "2019-12-09T16:43:41.201597Z"
    }
   },
   "outputs": [],
   "source": [
    "# INPUT & OUTPUT SHAPES\n",
    "INPUT_SHAPE = X_train.shape[1]\n",
    "OUTPUT_SHAPE = labelled_y_train.shape[1]\n",
    "\n",
    "print(INPUT_SHAPE)\n",
    "print(OUTPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALL MODEL: SHORT & SHALLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.213596Z",
     "start_time": "2019-12-09T16:43:41.210597Z"
    }
   },
   "outputs": [],
   "source": [
    "neurons = [2, 2, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.221596Z",
     "start_time": "2019-12-09T16:43:41.214596Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_small_model(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIG MODEL: WIDE & DEEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neurons = [256, 256, 256, 256, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = build_big_model(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOMEHWERE IN-BETWEEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neurons = [256, 128, 64, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = build_medium_model(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:41.366596Z",
     "start_time": "2019-12-09T16:43:41.361596Z"
    }
   },
   "outputs": [],
   "source": [
    "history = History()\n",
    "filepath= NAME + '--best.weights.keras'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_categorical_accuracy', \n",
    "                                             verbose=1, save_best_only=True, \n",
    "                                             save_weights_only=False, mode='auto',\n",
    "                                             save_freq=\"epoch\")\n",
    "\n",
    "stop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, patience=200, mode='auto')\n",
    "csv_logger = CSVLogger(NAME + '_training-log.log', separator=',', append=False)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                              mode='auto', cooldown=0, \n",
    "                              patience=10, min_lr=10e-10, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:45.190597Z",
     "start_time": "2019-12-09T16:43:41.367597Z"
    }
   },
   "outputs": [],
   "source": [
    "# TRAIN MODEL\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "X = X_train\n",
    "y = labelled_y_train\n",
    "\n",
    "model.fit(X, y, \n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[history, checkpoint, csv_logger, reduce_lr, stop],\n",
    "          verbose = 1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:45.914595Z",
     "start_time": "2019-12-09T16:43:45.207597Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:46.673595Z",
     "start_time": "2019-12-09T16:43:45.915595Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:46.678596Z",
     "start_time": "2019-12-09T16:43:46.674595Z"
    }
   },
   "outputs": [],
   "source": [
    "# RUN INFECTION CLASSIFIER IN PREDICTION MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:48.424597Z",
     "start_time": "2019-12-09T16:43:46.679597Z"
    }
   },
   "outputs": [],
   "source": [
    "## USE TRAINED MODEL TO RUN PREDICTIONS ON UNSEEN DATA\n",
    "yhat = model.predict(X_test, verbose=1, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:48.435597Z",
     "start_time": "2019-12-09T16:43:48.427597Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame(yhat, columns=['Normal', 'Inflammation', 'Infection', 'Severe inf', 'Unsure', 'Missing']).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:43:48.618595Z",
     "start_time": "2019-12-09T16:43:48.437597Z"
    }
   },
   "outputs": [],
   "source": [
    "# SHOW PREDICTION RESULTS\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "n_classes = 6\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y_test = labelled_y_test\n",
    "y_score = yhat\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
